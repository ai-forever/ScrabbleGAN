from importlib import import_module
import pickle as pkl
import cv2
import numpy as np
import pandas as pd
import os
import torch
from tqdm import tqdm
import argparse

from scgan.utils.data_utils import *
from scgan.utils.training_utils import ModelCheckpoint
from scgan.config import Config


class ImgGenerator:
    def __init__(self, checkpt_path, config, char_map_path, shrink_ratio=0.5,
        lexicon_paths=None, return_rgb=False):
        """
        :param checkpt_path: Path of the model checkpoint file to be used.
        :param config: Config with all the parameters to be used.
        :param char_map_path: Path to pkl-file with char_map dict.
        :param lexicon_paths: List of paths to lexicon txt. Default is None.
        :param shrink_ratio: The ratio of image resize by width (ScrabbleGAN by
            default generate too wide images.
        :return_rgb: Return RGB image.
        """
        self.return_rgb = return_rgb
        self.shrink_ratio = shrink_ratio
        self.config = config
        with open(char_map_path, 'rb') as f:
            char_map = pkl.load(f)
        self.char_map = char_map['char_map']
        print(f'Model: {config.architecture}')
        model_type = import_module('scgan.models.' + self.config.architecture)
        create_model = getattr(model_type, 'create_model')
        self.model = create_model(self.config, self.char_map, lexicon_paths)
        self.model.to(self.config.device)
        self.model.eval()
        # Load model weights
        self.model_checkpoint = ModelCheckpoint(config=self.config)
        self.model, _, _, _ = self.model_checkpoint.load(self.model, checkpt_path)

    def _shrink_images(self, images):
        """Resize image by width by shrink_ratio."""
        resized_images = []
        for img in images:
            h, w = img.shape[:2]
            resized_images.append(
                cv2.resize(img, (int(w * self.shrink_ratio), h), cv2.INTER_AREA)
            )
        return resized_images

    def _bgr2rgb(self, images):
        """Convert images to BGR."""
        rgb_images = []
        for img in images:
            rgb_images.append(
                cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            )
        return rgb_images

    def _renormalize_images(self, generated_imgs):
        """Renormalize generator outputs and return list of images."""
        images = []
        for img in generated_imgs:
            normalized_img = ((img + 1) * 255 / 2).astype(np.uint8)
            normalized_img = np.moveaxis(normalized_img, 0, -1)
            images.append(normalized_img)
        return images

    def _preprocess_words(self, word_list):
        """Preprocess input texts: remove out of vocabulary chars."""
        new_word_list = []
        for word in word_list:
            new_word = ''
            for char in word:
                if char in self.char_map:
                    new_word += char
                elif char.lower() in self.char_map:
                    new_word += char.lower()

            if len(new_word) == 0:
                new_word = ' '
            new_word_list.append(new_word)
        return new_word_list

    def generate(self, random_num_imgs=5, word_list=None, z=None):
        """
        Returns images generated by the trained generator model

        :param random_num_imgs: Number of images to be randomly generated using lexicon (only valid if word_list=None)
        :param word_list: List of words for which images need to be generated
        :param z: Noise vector determining the style of the images to be generated (32 dimension vector)
        """

        if word_list is None:
            b_size = random_num_imgs
        else:
            word_list = self._preprocess_words(word_list)
            b_size = len(word_list)

        with torch.no_grad():
            self.model.forward_fake(z=None, fake_y=word_list, b_size=b_size)

        images = self._renormalize_images(
            self.model.fake_img.squeeze(1).cpu().numpy())
        images = self._shrink_images(images)
        if self.return_rgb:
            images = self._bgr2rgb(images)
        return images, self.model.fake_y_decoded


def main(args):
    generator = ImgGenerator(
        checkpt_path=args.checkpoint_path,
        config=Config,
        return_rgb=args.return_rgb,
        shrink_ratio=args.shrink_ratio,
        char_map_path=args.char_map_path,
        lexicon_paths=args.lexicon_path
    )

    os.makedirs(args.output_path, exist_ok=True)

    img_paths = []
    labels = []
    data_iters = range(max(1, int(args.num_imgs/args.batch_size)))
    tqdm_data_iters = tqdm(data_iters, leave=False)
    for data_iter in tqdm_data_iters:
        generated_imgs, word_labels = generator.generate(args.batch_size)
        for idx, (label, img) in enumerate(zip(word_labels, generated_imgs)):
            img_name = f'{data_iter}-{idx}.png'
            img_path = os.path.join(args.output_path, img_name)
            cv2.imwrite(img_path, img)

            img_path_truncated = os.path.join(
                os.path.basename(args.output_path), img_name)
            img_paths.append(img_path_truncated)
            labels.append(label)

    # save csv
    list_dict = {'filename': img_paths, 'text': labels}
    df = pd.DataFrame(list_dict)
    csv_path = os.path.join(
        os.path.dirname(args.output_path),
        f'{os.path.basename(args.output_path)}.csv'
    )
    df.to_csv(csv_path, index=False)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--checkpoint_path", required=True, type=str,
                        help="Path of the model checkpoint file to be used")
    parser.add_argument("--return_rgb", action='store_true',
                        help="To switch channels of generated images.")
    parser.add_argument("--shrink_ratio", type=float, default=0.5,
                        help="The resize ratio of output images by width.")
    parser.add_argument("--char_map_path", required=True, type=str,
                        help="Path of the file with character mapping to be used")
    parser.add_argument("--num_imgs", required=True, type=int,
                        help="number of sample points")
    parser.add_argument("--lexicon_path", action='append', required=True,
                        type=str, help="Path to the lexicon txt. Can be passed"
                        " multiple times")
    parser.add_argument("--output_path", required=True, type=str,
                        help="Directory to save generated images")
    parser.add_argument("--batch_size", required=False, type=int,
                        default=1, help="Batch size")
    args = parser.parse_args()

    main(args)
