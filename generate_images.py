from importlib import import_module
import pickle as pkl
import cv2
import numpy as np
import pandas as pd
import os
from tqdm import tqdm

from utils.data_utils import *
from utils.training_utils import ModelCheckpoint
from config import Config
import argparse
import matplotlib.pyplot as plt


class ImgGenerator:
    def __init__(self, checkpt_path, config, char_map, lexicon_paths):
        """
        :param checkpt_path: Path of the model checkpoint file to be used
        :param config: Config with all the parameters to be used
        """

        self.config = config
        self.char_map = char_map
        print(f'Model: {config.architecture}')
        model_type = import_module('models.' + self.config.architecture)
        create_model = getattr(model_type, 'create_model')
        self.model = create_model(self.config, self.char_map, lexicon_paths)
        self.model.to(self.config.device)
        self.model.eval()
        # Load model weights
        self.model_checkpoint = ModelCheckpoint(config=self.config)
        self.model, _, _, _ = self.model_checkpoint.load(self.model, checkpt_path)

    def generate(self, random_num_imgs=5, word_list=None, z=None):
        """
        Returns images generated by the trained generator model

        :param random_num_imgs: Number of images to be randomly generated using lexicon (only valid if word_list=None)
        :param word_list: List of words for which images need to be generated
        :param z: Noise vector determining the style of the images to be generated (32 dimension vector)
        """

        if word_list is None:
            b_size = random_num_imgs
        else:
            b_size = len(word_list)

        with torch.no_grad():
            self.model.forward_fake(z=None, fake_y=word_list, b_size=b_size)

        return self.model.fake_img.squeeze(1).cpu().numpy(), self.model.fake_y_decoded


def main(args):
    with open(args.char_map_path, 'rb') as f:
        char_map = pkl.load(f)
    char_map = char_map['char_map']

    generator = ImgGenerator(
        checkpt_path=args.checkpoint_path,
        config=Config,
        char_map=char_map,
        lexicon_paths=args.lexicon_path
    )

    os.makedirs(args.output_path, exist_ok=True)

    img_paths = []
    labels = []
    data_iters = range(max(1, int(args.num_imgs/args.batch_size)))
    tqdm_data_iters = tqdm(data_iters, leave=False)
    for data_iter in tqdm_data_iters:
        generated_imgs, word_labels = generator.generate(args.batch_size)
        for idx, (label, img) in enumerate(zip(word_labels, generated_imgs)):
            normalized_img = ((img + 1) * 255 / 2).astype(np.uint8)
            normalized_img = np.moveaxis(normalized_img, 0, -1)

            img_name = f'{data_iter}-{idx}.png'
            img_path = os.path.join(args.output_path, img_name)
            cv2.imwrite(img_path, cv2.cvtColor(normalized_img, cv2.COLOR_RGB2BGR))

            img_path_truncated = os.path.join(
                os.path.basename(args.output_path), img_name)
            img_paths.append(img_path_truncated)
            labels.append(label)

    # save csv
    list_dict = {'filename': img_paths, 'text': labels}
    df = pd.DataFrame(list_dict)
    csv_path = os.path.join(
        os.path.dirname(args.output_path),
        f'{os.path.basename(args.output_path)}.csv'
    )
    df.to_csv(csv_path, index=False) 


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--checkpoint_path", required=True, type=str,
                        help="Path of the model checkpoint file to be used")
    parser.add_argument("--char_map_path", required=True, type=str,
                        help="Path of the file with character mapping to be used")
    parser.add_argument("--num_imgs", required=True, type=int,
                        help="number of sample points")
    parser.add_argument("--lexicon_path", action='append', required=True,
                        type=str, help="Path to the lexicon txt. Can be passed"
                        " multiple times")
    parser.add_argument("--output_path", required=True, type=str,
                        help="Directory to save generated images")
    parser.add_argument("--batch_size", required=False, type=int,
                        default=1, help="Batch size")
    args = parser.parse_args()

    main(args)
